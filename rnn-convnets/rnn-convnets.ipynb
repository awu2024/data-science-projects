{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1242e77c-6a95-4d2d-bb29-4e22adb888e8",
   "metadata": {},
   "source": [
    "# RNN and ConvNets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2458c5e-58ef-4827-91c0-a261ce858e0e",
   "metadata": {},
   "source": [
    "The data file ”data.csv” contains 3 time series x1, x2, and y along with the corresponding date column. The data ranges from beginning of 2019 to the end of Feb. of 2020. The objective of this problem is to make predictions for y for March 1st and 2nd in 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1fa1a-40e7-432d-a6e4-7f678f437199",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Conv1D\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.layers import Dropout, Flatten,MaxPooling1D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras.utils import to_categorical # np_utils\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Read the csv file\n",
    "df = pd.read_csv('timeseriesData.csv')\n",
    "# df.interpolate(method='linear', inplace=True)\n",
    "# df.dropna(subset=['Date'], inplace=True)\n",
    "df.tail(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00cfc2f-5caa-4d39-a82b-475c0637f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88724e51-47de-4cb6-aebc-1b1a3b467345",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "# Visualize the Data\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = df['Date'], y = df['x1'], name = \"x1\"))\n",
    "fig.add_trace(go.Scatter(x = df['Date'], y = df['x2'], name = 'x2'))\n",
    "fig.add_trace(go.Scatter(x = df['Date'], y = df['y'], name = 'y'))\n",
    "fig.update_layout(title = \"x1, x2, and y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818bb4e8-6a40-4d55-a786-f9464a8db85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert x1 and x2 into numpy array\n",
    "x_val_1 = df.loc[:,['x1', 'x2']].values\n",
    "# Train 70% data, 15% for validation, 15% for test\n",
    "trainPortion = round(x_val_1.shape[0]*0.7)\n",
    "valPortion = round(x_val_1.shape[0]*0.15)\n",
    "trainData = x_val_1[:trainPortion]\n",
    "valData = x_val_1[trainPortion:trainPortion + valPortion]\n",
    "testData = x_val_1[trainPortion + valPortion:]\n",
    "print('We have %d training, %d validation, and %d test points' %(len(trainData), len(valData), len(testData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af50fcc-1da7-4035-a9c9-6085a3529473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data subsets of x1 and x2\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = df[:trainPortion]['Date'], y = df[:trainPortion]['y'], name = \"Training Set\"))\n",
    "fig.add_trace(go.Scatter(x=df[trainPortion:trainPortion + valPortion]['Date'],\n",
    "                         y = df[trainPortion:trainPortion + valPortion]['y'],\n",
    "                         name = 'Validation Set'))\n",
    "fig.add_trace(go.Scatter(x=df[trainPortion + valPortion:]['Date'],\n",
    "                         y = df[trainPortion + valPortion:]['y'],\n",
    "                         name = 'Test Set'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cfa2a8-0b7c-490f-aa49-d68871dcb3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print x1 and x2 shape\n",
    "print(trainData.shape)\n",
    "print(valData.shape)\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234fe91-46e6-41be-a268-7061e7f812ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize x1 and x2 data\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "sc.fit(trainData)\n",
    "trainNorm = sc.transform(trainData)\n",
    "valNorm = sc.transform(valData)\n",
    "testNorm = sc.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f60981-9226-4151-a558-e2ed67fa9318",
   "metadata": {},
   "source": [
    "1. Explore regular feedforward neural network models for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff95e1-e919-46c3-89e4-713e26b3e3f1",
   "metadata": {},
   "source": [
    "(a) Report the unnormalized MAE of the test set on your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f03849-3af1-49bb-a05e-cd2fb834d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y into numpy array\n",
    "y_val = df.loc[:,'y'].values\n",
    "trainY = y_val[:trainPortion]\n",
    "valY = y_val[trainPortion:trainPortion + valPortion]\n",
    "testY= y_val[trainPortion + valPortion:]\n",
    "print('We have %d training, %d validation, and %d test points' %(len(trainData), len(valData), len(testData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e9217-f195-48f3-92e5-0ff8a7649f32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find MAE with regular feedforward network\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape = (2,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mae', optimizer='adam', metrics =['mean_absolute_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa5b14-7091-4ad7-aa22-5ebc64b6c26f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = EarlyStopping(monitor='val_loss',patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "callbacks_list = [checkpoint]            \n",
    "network = model.fit(trainNorm, trainY, validation_data=(valNorm, valY),\n",
    "                    epochs=100, batch_size=64,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1aae5-cd3d-46b1-b5f4-12f28a7c36f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testNormPred= model.predict(testNorm)\n",
    "mae = tf.keras.metrics.MeanAbsoluteError()\n",
    "testMae = mae(testY.reshape(-1,1), testNormPred).numpy()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=testNormPred.reshape(-1,),\n",
    "                         mode='markers',\n",
    "                         name='Model Predictions on Test Set'))\n",
    "fig.add_trace(go.Scatter(y=testY.reshape(-1,),\n",
    "                         mode='markers',\n",
    "                         name='Target Values for the Test Set'))\n",
    "fig.update_layout(title_text='Unnormalized MAE Test = '\n",
    "                  + str(np.mean(testMae)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be115dbe-35ee-4e44-8bd8-32002813d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best model and has an unnormalized MSE of: ', testMae) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2b256-6496-4786-8f54-1df4b7c74372",
   "metadata": {},
   "source": [
    "(b) Plot the loss curves for training and validation sets for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98edf51f-4480-4a7c-a1de-2ba07c9728d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot x1 and x2 loss curves\n",
    "valMae = round(network.history['val_loss'][-1],2)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=network.history['loss'],\n",
    "                         mode='lines',\n",
    "                         name='Training Error'))\n",
    "fig.add_trace(go.Scatter(y=network.history['val_loss'],\n",
    "                         mode='lines',\n",
    "                         name='Validation Error'))\n",
    "fig.update_layout(yaxis_title = 'Mean Absolute Error',\n",
    "                  xaxis_title = 'epoch',\n",
    "                  title_text='Normalized MAE Validation = ' +\n",
    "                  str(valMae))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8240bc81-4342-497f-9c41-d1304616d882",
   "metadata": {},
   "source": [
    "(c) What are the predicted values of y for March 1st and March 2nd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199a4ed-70a0-47e1-a814-711a5cb84da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict March 1st and March 2nd\n",
    "march_values = testNorm[-1]\n",
    "march1 = model.predict(march_values.reshape(1, 2))\n",
    "\n",
    "march2 = model.predict(march_values.reshape(1,2))\n",
    "march2\n",
    "\n",
    "print(f'The predicted values of y for March 1st and March 2nd are: {march1[-1]} and {march2[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fbef96-09b2-40b2-962f-ac1dab07e239",
   "metadata": {},
   "source": [
    "2. Explore recurrent neural network models for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfff1c1-f5bd-4680-95cc-7632fe186003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for creating sequences\n",
    "def createSeq(dataset_x, dataset_y, look_back, foresight):\n",
    "    X, Y = [], []    \n",
    "    for i in range(len(dataset_x)-look_back-foresight):\n",
    "        obs = dataset_x[i:(i+look_back), :] #Sequence of \"look_back\"       \n",
    "        X.append(obs)                   #Append stock price value occurring \"foresight+1\"\n",
    "        Y.append(dataset_y[i + (look_back+foresight)])     \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113bedd9-7424-4b38-8c3f-c6067e0c2b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for data\n",
    "trainNormX, trainNormY = createSeq(trainNorm, trainY, look_back = 7, foresight = 1)\n",
    "valNormX, valNormY = createSeq(valNorm, valY, look_back = 7, foresight = 1)\n",
    "testNormX, testNormY = createSeq(testNorm, testY, look_back = 7, foresight = 1)\n",
    "print(trainNormX.shape, trainNormY.shape)\n",
    "print(valNormX.shape, valNormY.shape)\n",
    "print(testNormX.shape, testNormY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fefe1-48e9-4348-8f52-80560134e0c2",
   "metadata": {},
   "source": [
    "(a) Report the unnormalized MAE of the test set on your best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025b7de-cf14-4d9c-ae00-f85a4dbd28bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find MAE with RNN\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(7,2), dropout=0.1, recurrent_dropout=0.1)) # input_shape(,n) n is the number of features\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mae', optimizer='adam', metrics =['mean_absolute_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205becbc-2962-463b-906b-9560f1351f37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = EarlyStopping(monitor='val_loss',patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "callbacks_list = [checkpoint]            \n",
    "network = model.fit(trainNormX, trainNormY, validation_data=(valNormX, valNormY),\n",
    "                    epochs=100, batch_size=64,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a075e428-7baf-4d96-9d75-97df2a5ff407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testNormPred= model.predict(testNormX)\n",
    "testPred = testNormPred\n",
    "testY = testNormY.reshape(-1,1)\n",
    "mae = tf.keras.metrics.MeanAbsoluteError()\n",
    "testMae = mae(testY, testPred).numpy()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=testPred.reshape(-1,),\n",
    "                         mode='markers',\n",
    "                         name='Model Predictions on Test Set'))\n",
    "fig.add_trace(go.Scatter(y=testY.reshape(-1,),\n",
    "                         mode='markers',\n",
    "                         name='Target Values for the Test Set'))\n",
    "fig.update_layout(title_text='Unnormalized MAE Test = '\n",
    "                  + str(np.mean(testMae)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd474f77-da38-468a-9858-b17b96eae389",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best model and has an unnormalized MSE of: ', testMae) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562a1a2-8527-4896-8250-0a845f43868c",
   "metadata": {},
   "source": [
    "(b) Plot the loss curves for training and validation sets for the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2353b7ad-ecb8-48da-a040-495d747af506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot x1 and x2 loss curves\n",
    "valMae = round(network.history['val_loss'][-1],2)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=network.history['loss'],\n",
    "                         mode='lines',\n",
    "                         name='Training Error'))\n",
    "fig.add_trace(go.Scatter(y=network.history['val_loss'],\n",
    "                         mode='lines',\n",
    "                         name='Validation Error'))\n",
    "fig.update_layout(yaxis_title = 'Mean Absolute Error',\n",
    "                  xaxis_title = 'epoch',\n",
    "                  title_text='Normalized MAE Validation = ' +\n",
    "                  str(valMae))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad67976-3c36-467a-92c8-1b8ab863197c",
   "metadata": {},
   "source": [
    "(c) What are the predicted values of y for March 1st and March 2nd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e6514-084b-41ac-afe1-b5415ec66db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict March 1st and March 2nd\n",
    "march_values = testNormX[-2]\n",
    "march1 = model.predict(march_values.reshape(1, 7, 2))\n",
    "\n",
    "march_shift = testNormX[-1]\n",
    "march2 = model.predict(march_shift.reshape(1, 7, 2))\n",
    "\n",
    "print(f'The predicted values of y for March 1st and March 2nd are: {march1[-1]} and {march2[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f1211b-b2c5-44dd-9caf-52e7886350ca",
   "metadata": {},
   "source": [
    "3. Explore 1d convolutional neural network models for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ae0fe-790c-406a-b62e-7cfb5556ae2a",
   "metadata": {},
   "source": [
    "(a) Report the unnormalized MAE of the test set on your best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984447fa-9371-488c-b1e4-7ec4b8abb25e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find MAE of x1 and x2 with Conv1D\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, kernel_size=5, input_shape=(7,2), activation = 'relu')) # input_shape(,n) n is the number of features\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mae', optimizer='adam', metrics =['mean_absolute_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad947c-fda8-4837-b69a-ac2edeb9c565",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = EarlyStopping(monitor='val_loss',patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "callbacks_list = [checkpoint]\n",
    "network = model.fit(trainNormX, trainNormY, validation_data=(valNormX, valNormY),\n",
    "                    epochs=100, batch_size=64,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a634c-8e92-47ee-a92a-ac222c9f7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "testNormPred= model.predict(testNormX)\n",
    "testPred = testNormPred\n",
    "testY = testNormY\n",
    "mae = tf.keras.metrics.MeanAbsoluteError()\n",
    "testMae = mae(testY, testPred).numpy()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=testPred.reshape(-1,),\n",
    "                         mode='markers',\n",
    "                         name='Model Predictions on Test Set'))\n",
    "fig.add_trace(go.Scatter(y=testY.reshape(-1,),\n",
    "                         mode='markers',\n",
    "                         name='Target Values for the Test Set'))\n",
    "fig.update_layout(title_text='Unnormalized MAE Test = '\n",
    "                  + str(np.mean(testMae)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d20d9a-63a6-4afc-8978-f2074a317573",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best model and has an unnormalized MSE of: ', testMae) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c8d90-d4d5-4fbf-a60d-b9cf2e41624b",
   "metadata": {},
   "source": [
    "(b) Plot the loss curves for training and validation sets for the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135112ec-7f2f-49d9-a797-053a34f8561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot x1 and x2 loss curves\n",
    "valMae = round(network.history['val_loss'][-1],2)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=network.history['loss'],\n",
    "                         mode='lines',\n",
    "                         name='Training Error'))\n",
    "fig.add_trace(go.Scatter(y=network.history['val_loss'],\n",
    "                         mode='lines',\n",
    "                         name='Validation Error'))\n",
    "fig.update_layout(yaxis_title = 'Mean Absolute Error',\n",
    "                  xaxis_title = 'epoch',\n",
    "                  title_text='Normalized MAE Validation = ' +\n",
    "                  str(valMae))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caca035-0c75-4b97-b63d-df610bcf6564",
   "metadata": {},
   "source": [
    "(c) What are the predicted values of y for March 1st and March 2nd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e77e62-198f-47e7-8fa8-4c046b3a50a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict March 1st and March 2nd\n",
    "march_values = testNormX[-2]\n",
    "march1 = model.predict(march_values.reshape(1, 7, 2))\n",
    "\n",
    "march_shift = testNormX[-1]\n",
    "march2 = model.predict(march_shift.reshape(1, 7, 2))\n",
    "\n",
    "print(f'The predicted values of y for March 1st and March 2nd are: {march1[-1]} and {march2[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e387732-4189-47d9-a671-d8df94c6570f",
   "metadata": {},
   "source": [
    "In this problem, you need to apply all ML foundation and techniques that you’ve learned in the program so far. These include but are not limited to: <b>data cleaning, data imputation for missing values, full exploratory analysis along with relative visualisations, statistical tests, data normalization, data split, addressing overfitting/underfitting, tuning hyperparameters, model assessment, etc.. Feel free to apply the techniques you’ve learned in your time-series course here when relevant.</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-py312]",
   "language": "python",
   "name": "conda-env-tf-py312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
